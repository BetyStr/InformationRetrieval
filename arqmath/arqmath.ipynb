{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfQo2UKpZ9jT"
   },
   "source": [
    "# Alternative Second Term Project: ARQMath Collection, Answer Retrieval Task\n",
    "\n",
    "‚ÄúIn a recent study, Mansouri et al. found that 20% of mathematical queries in a general-purpose search engine were expressed as well-formed questions, a rate ten times higher than that for all queries submitted. Results such as these and the presence of Community Question Answering sites such as Math Stack Exchange suggest there is interest in finding answers to mathematical questions posed in natural language, using both text and mathematical notation.‚Äù [1]\n",
    "\n",
    "‚Äú[ARQMath](https://www.cs.rit.edu/~dprl/ARQMath/) is a co-operative evaluation exercise aiming to advance math-aware search and the semantic analysis of mathematical notation and texts.‚Äù [2]\n",
    "\n",
    " ![Answer Retrieval Task](https://www.cs.rit.edu/~dprl/ARQMath/assets/images/screen-shot-2019-09-09-at-11.11.57-pm-2656x1229.png)\n",
    "\n",
    "Your tasks, reviewed by your colleagues and the course instructors, are the following:\n",
    "\n",
    "1.   *Implement a supervised ranked retrieval system*, [3, Chapter¬†15] which will produce a list of documents from the ARQMath collection in a descending order of relevance to a query from the ARQMath collection. You SHOULD use training and validation relevance judgements from the ARQMath collection in your information retrieval system. Test judgements MUST only be used for the evaluation of your information retrieval system.\n",
    "\n",
    "2.   *Document your code* in accordance with [PEP 257](https://www.python.org/dev/peps/pep-0257/), ideally using [the NumPy style guide](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard) as seen in the code from exercises.  \n",
    "     *Stick to a consistent coding style* in accordance with [PEP 8](https://www.python.org/dev/peps/pep-0008/).\n",
    "\n",
    "3.   *Reach at least 10% mean average precision at 10* [3, Section¬†8.4] with your system on the ARQMath collection. You are encouraged to use techniques for tokenization, [3, Section¬†2.2] document representation [3, Section¬†6.4], tolerant retrieval [3, Chapter¬†3], relevance feedback, query expansion, [3, Chapter¬†9], learning to rank [3, Chapter 15], and others discussed in the course.\n",
    "\n",
    "4.   _[Upload an .ipynb file](https://is.muni.cz/help/komunikace/spravcesouboru#k_ss_1) with this Jupyter notebook to the homework vault in IS MU._ You MAY also include a brief description of your information retrieval system and a link to an external service such as [Google Colaboratory](https://colab.research.google.com/), [DeepNote](https://deepnote.com/), or [JupyterHub](https://iirhub.cloud.e-infra.cz/).\n",
    "\n",
    "The best student systems will enter the ARQMath competition and help develop the new search engine for [the Math StackExchange question answering forum](http://math.stackexchange.com/). This is not only useful, but also a nice reference for your CVs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruSklUM7e5aj"
   },
   "source": [
    "[1] Zanibbi, R. et al. [Overview of ARQMath 2020 (Updated Working Notes Version): CLEF Lab on Answer Retrieval for Questions on Math](http://ceur-ws.org/Vol-2696/paper_271.pdf). In: *Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum*. 2020.\n",
    "\n",
    "[2] Zanibbi, R. et al. [*ARQMath: Answer Retrieval for Questions on Math (2022)*](https://www.cs.rit.edu/~dprl/ARQMath/index.html). Rochester Institute of Technology. 2022.\n",
    "\n",
    "[3] Manning, Christopher D., Prabhakar Raghavan, and Hinrich Sch√ºtze. [*Introduction to information retrieval*](https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf). Cambridge university press, 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmpR8qpTZwyP"
   },
   "source": [
    "## Loading the ARQMath collection\n",
    "\n",
    "First, we will install [our library](https://gitlab.fi.muni.cz/xstefan3/pv211-utils) and load the ARQMath collection. If you are interested, you can take a peek at [how we preprocessed the raw ARQMath collection](https://drive.google.com/file/d/1ZFJyBHUuMe4CkwV1HGKYg_F-Fk_PSW9R/view) to the final dataset that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "inUAfc6TQMVJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/MIR-MU/pv211-utils.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdM90O8nlUn5"
   },
   "source": [
    "The questions and answers from the ARQMath collection, and the queries from the from the answer retrieval task of ARQMath 2020 contain both text and mathematical formulae. We have prepared several encodings of the text and mathematical, which you can choose from:\n",
    "\n",
    "- `text` ‚Äì Plain text, which contains no mathematical formulae. *Nice and easy*, but you are losing all information about the math:\n",
    "\n",
    "    > Finding value of  such that ...\n",
    "\n",
    "- `text+latex` ‚Äì Plain text with mathematical formulae in LaTeX surrounded by dollar signs. Still quite nice to work:\n",
    "\n",
    "    > Finding value of \\$c\\$ such that ...\n",
    "\n",
    "- `text+tangentl` ‚Äì Plain text with mathematical formulae in [the mathtuples format][5] of [the Tangent-L system][6]. Like LaTeX, the mathtuples format encodes how a mathematical formula looks, but is fuzzier in order to improve recall.\n",
    "\n",
    "    > Finding value of #(start)# #(v!c,!0,-)# #(v!c,!0)# #(end)# such that ...\n",
    "\n",
    "- `text+prefix` ‚Äì Plain text with mathematical formulae in [the prefix format][1]. Unlike LaTeX, which encodes how a mathematical formula looks, the prefix format encodes the semantic content of the formulae using [the Polish notation][2].\n",
    "\n",
    "    > Finding value of V!ùëê such that ...\n",
    "\n",
    "- `xhtml+latex` ‚Äì XHTML text with mathematical formulae in LaTeX, surrounded by the `<span class=\"math-container\">` tags:\n",
    "\n",
    "    > ``` html\n",
    "    > <p>Finding value of <span class=\"math-container\">$c$</span> such that ...\n",
    "    > ```\n",
    "\n",
    "- `xhtml+pmml` ‚Äì XHTML text with mathematical formulae in the [Presentation MathML][4] XML format, which encodes how a mathematical formula looks:\n",
    "\n",
    "    > ``` html\n",
    "    > <p>Finding value of <math><mi>c</mi></math> such that'\n",
    "    > ```\n",
    "\n",
    "- `xhtml+cmml` ‚Äì XHTML text with mathematical formulae in the [Content MathML][3] XML format, which encodes the semantic content of a formula. This format is *much more difficult to work with*, but it allows you to represent mathematical formulae structurally and use XML Retrieval [3, Chapter 10].\n",
    "\n",
    "    > ``` html\n",
    "    > <p>Finding value of <math><ci>ùëê</ci></math> such that ...\n",
    "    > ```\n",
    "\n",
    " [1]: http://ceur-ws.org/Vol-2696/paper_235.pdf#page=5\n",
    " [2]: https://en.wikipedia.org/wiki/Polish_notation\n",
    " [3]: https://www.w3.org/TR/MathML2/chapter4.html\n",
    " [4]: https://www.w3.org/TR/MathML2/chapter3.html\n",
    " [5]: https://github.com/fwtompa/mathtuples\n",
    " [6]: http://ceur-ws.org/Vol-2936/paper-05.pdf#page=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "azYtWfRRpoxB"
   },
   "outputs": [],
   "source": [
    "text_format = 'text+latex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y845E0ePZqeH"
   },
   "source": [
    "### Loading the answers\n",
    "\n",
    "Next, we will define a class named `Answer` that will represent a preprocessed answer from the ARQMath 2020 collection. Tokenization and preprocessing of the `body` attribute of the individual answers as well as the creative use of the `upvotes` and `is_accepted` attributes is left to your imagination and craftsmanship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J5qAXnECFPLB"
   },
   "outputs": [],
   "source": [
    "from pv211_utils.arqmath.entities import ArqmathAnswerBase\n",
    "\n",
    "class Answer(ArqmathAnswerBase):\n",
    "    \"\"\"A preprocessed answer from the ARQMath 2020 collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        A unique identifier of the answer among all questions and answers.\n",
    "    body : str\n",
    "        The text of the answer, including mathematical formulae.\n",
    "    upvotes : int\n",
    "        The number of upvotes for the answer.\n",
    "    is_accepted : bool\n",
    "        If the answer has been accepted by the poster of the question.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, document_id: str, body: str, upvotes: int,\n",
    "                 is_accepted: bool):\n",
    "        super().__init__(document_id, body, upvotes, is_accepted)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.body\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HfRrW7O6U5wb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.datasets import ArqmathDataset\n",
    "\n",
    "data = ArqmathDataset(year=2021, text_format=text_format)\n",
    "answers = data.load_answers(Answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjzTmnjcrJVQ"
   },
   "source": [
    "### Loading the questions\n",
    "\n",
    "Next, we will define a class named `Question` that will represent a preprocessed question from the ARQMath 2020 collection. Tokenization and preprocessing of the `title` and `body` attributes of the individual questions as well as the creative use of the `tags`, `upvotes`, `views`, and `answers` attributes is left to your imagination and craftsmanship.\n",
    "\n",
    "We will not be returning these questions from our search engine, but we could use them for example to look up similar existing questions to a query and then return the answers to these existing questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bzxEgAlDFPLI"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pv211_utils.arqmath.entities import ArqmathQuestionBase\n",
    "\n",
    "class Question(ArqmathQuestionBase):\n",
    "    \"\"\"A preprocessed question from the ARQMath 2020 collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        A unique identifier of the question among all questions and answers.\n",
    "    title : str\n",
    "        The title of the question, including mathematical formulae.\n",
    "    body : str\n",
    "        The text of the question, including mathematical formulae.\n",
    "    tags : list of str\n",
    "        Tags describing the topics of the question.\n",
    "    upvotes : int\n",
    "        The number of upvotes for the question.\n",
    "    views : int\n",
    "        The number of views for the question.\n",
    "    answers : list of Answer\n",
    "        The answers for the question.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, document_id: str, title: str, body: str, tags: List[str],\n",
    "                 upvotes: int, views: int, answers: List[Answer]):\n",
    "        super().__init__(document_id, title, body, tags, upvotes, views, answers)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.title} {self.body}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uUgfKxugscxo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_questions_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_questions_text+latex.json.gz\n"
     ]
    }
   ],
   "source": [
    "questions = data.load_questions(Question)\n",
    "answer_to_question = {\n",
    "    answer: question\n",
    "    for question in questions.values()\n",
    "    for answer in question.answers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwYwHs-MpD1_"
   },
   "source": [
    "### Loading the queries\n",
    "Next, we will define a class named `Query` that will represent a preprocessed query from the answer retrieval task of ARQMath 2020. Tokenization and preprocessing of the `title` and `body` attributes of the individual questions as well as the creative use of the `tags` attribute is left to your imagination and craftsmanship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-aAREbRMXeJ"
   },
   "source": [
    "We will load queries into the `train_queries` and `validation_queries` [ordered dictionaries](https://docs.python.org/3.8/library/collections.html#collections.OrderedDict). Each query is an instance of the `Query` class that we have just defined. You should use `train_queries`, `validation_queries`, and *relevance judgements* (see the next section) for training your supervised information retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciMVC1ufImzf"
   },
   "source": [
    "If you are training just a single machine learning model without any early stopping or hyperparameter optimization, you can use `bigger_train_queries` as the input.\n",
    "\n",
    "If you are training a single machine learning model with early stopping or hyperparameter optimization, you can use `train_queries` for training your model and `validation_queries` to stop early or to select the optimal hyperparameters for your model. You can then use `bigger_train_queries` to train the model with the best number of epochs or the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ss39Vn70FPLP"
   },
   "outputs": [],
   "source": [
    "from pv211_utils.arqmath.entities import ArqmathQueryBase\n",
    "\n",
    "class Query(ArqmathQueryBase):\n",
    "    \"\"\"A preprocessed query from the answer retrieval task of ARQMath 2020.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_id : int\n",
    "        A unique identifier of the query.\n",
    "    title : str\n",
    "        The title of the query, including mathematical formulae.\n",
    "    body : str\n",
    "        The text of the query, including mathematical formulae.\n",
    "    tags : list of str\n",
    "        Tags describing the topics of the query.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, query_id: int, title: str, body: str, tags: List[str]):\n",
    "        super().__init__(query_id, title, body, tags)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.title} {self.body}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8qcyQUNRqRTr"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "\n",
    "train_queries = data.load_train_queries(Query)\n",
    "validation_queries = data.load_validation_queries(Query)\n",
    "\n",
    "bigger_train_queries = OrderedDict(chain(train_queries.items(), validation_queries.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA-0vN4swjwD"
   },
   "source": [
    "For a demonstration, we will look at query number 5. This is a query that is relatively easy to answer using just the text of the query, not the mathematical formulae. The user is asking for a computational solution to an interesting puzzle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8psrfOlGH-hM"
   },
   "source": [
    "### Loading the relevance judgements\n",
    "Next, we will load train and validation relevance judgements into the `train_judgements` and `validation_judgement` sets. Relevance judgements specify, which answers are relevant to which queries. You should use relevance judgements for training your supervised information retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zzV99yDIrJf"
   },
   "source": [
    "\n",
    "If you are training just a single machine learning model without any early stopping or hyperparameter optimization, you can use `bigger_train_judgements` as the input.\n",
    "\n",
    "If you are training a single machine learning model with early stopping or hyperparameter optimization, you can use `train_judgements` for training your model and `validation_judgements` to stop early or to select the optimal hyperparameters for your model. You can then use `bigger_train_judgements` to train the model with the best number of epochs or the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MbEYf0zwKz44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.arqmath.loader import load_judgements\n",
    "\n",
    "train_judgements = data.load_train_judgements()\n",
    "validation_judgements = data.load_validation_judgements()\n",
    "\n",
    "bigger_train_judgements = train_judgements | validation_judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3I5Wv_9ynfI"
   },
   "source": [
    "For a demonstration, we will look at query number 5 and show a relevant answer to the query and a non-relevant answer to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnrzyrL2Fam3"
   },
   "source": [
    "## Implementation of your information retrieval system\n",
    "\n",
    "You can try the [preprocessing][1] and [systems][2] that are [available in our library][1], but feel free to implement your own.\n",
    "\n",
    " [1]: https://github.com/MIR-MU/pv211-utils/tree/main/pv211_utils/preprocessing\n",
    " [2]: https://github.com/MIR-MU/pv211-utils/tree/main/pv211_utils/systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from rank_bm25 import BM25Plus\n",
    "import heapq\n",
    "from pv211_utils.cranfield.irsystem import CranfieldIRSystemBase\n",
    "from tqdm import tqdm\n",
    "from typing import Iterable, Set, List, OrderedDict\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "from gensim.utils import simple_preprocess\n",
    "from collections import OrderedDict\n",
    "from pv211_utils.entities import DocumentBase, QueryBase\n",
    "from pv211_utils.irsystem import IRSystemBase\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training is not the perfect word for this purpose ... in this context it only means encoding socuments to vectors\n",
    "# if training is True then the data will be transformed again which takes more than 2 hours (depends on GPU, sometimes even 6 hours)\n",
    "# if training is False then the data and model will be loaded (see cell with comment \"loading\")\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel = SentenceTransformer('all-mpnet-base-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    # it is faster when you encoding multiple document in one time\n",
    "    semantic_document_vectors = []\n",
    "    lst_loop = []\n",
    "    counter = 0\n",
    "    for doc in tqdm(list(answers.values())):\n",
    "        lst_loop.append(doc.body)\n",
    "        counter += 1\n",
    "        if counter == 150:\n",
    "            semantic_document_vectors.extend(mmodel.encode(lst_loop, convert_to_tensor=True))\n",
    "            lst_loop = []\n",
    "            counter = 0\n",
    "\n",
    "    semantic_document_vectors.extend(mmodel.encode(lst_loop, convert_to_tensor=True))\n",
    "    \n",
    "    semantic_document_vectors_on_cpu = []\n",
    "    for i in tqdm(semantic_document_vectors):\n",
    "        lstlst.append(i.to(\"cpu\"))\n",
    "        \n",
    "    vectors = torch.stack(semantic_document_vectors_on_cpu).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optional save\n",
    "# if training:\n",
    "#     with open('arqmath_document_vectors_latex.npy', 'wb') as f:\n",
    "#         np.save(f, my_ssssssemantic_document_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading if you can (file is too big for odevzdavaren)\n",
    "if not training:\n",
    "    with open('arqmath_document_vectors_latex.npy', 'rb') as f:\n",
    "        vectors = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IRSystem(CranfieldIRSystemBase):\n",
    "    \"\"\"\n",
    "    Class for informational retrieval system that use sentence tranformers and BM25PlusSystem\n",
    "    Parameters\n",
    "    ----------\n",
    "    documents: OrderedDict\n",
    "        Input documents\n",
    "    \"\"\" \n",
    "    def __init__(self, documents):\n",
    "        index_to_document = dict(enumerate(documents.values()))\n",
    "        self.index_to_document = index_to_document\n",
    "        self._count = 0\n",
    "\n",
    "    def search(self, query: Query):\n",
    "        # for printing progress bar (number of queries are 100)\n",
    "        self._count += 1\n",
    "        if self._count % 5 == 0:\n",
    "            print(self._count, end=\"% \")\n",
    "        \n",
    "        # sentence transformer\n",
    "        similarities_dict = {}        \n",
    "        query_transformer = mmodel.encode(\"Title: \" + query.title + \"\\nBody: \" + query.body)\n",
    "        cosine_sim = vectors.dot(query_transformer)\n",
    "        similarities_dict = {i: val for i, val in enumerate(cosine_sim)}\n",
    "\n",
    "        result = [(key, value) for key, value in similarities_dict.items()]\n",
    "        top = heapq.nlargest(10, result, key=lambda item: item[1])\n",
    "\n",
    "        # re-ranked top 10 values based on BM25Plus\n",
    "        ans = OrderedDict()\n",
    "        for document_number, _ in top:\n",
    "            document = self.index_to_document[document_number]\n",
    "            ans.update({document_number: document})\n",
    "        bm = my_BM25PlusSystem(ans)\n",
    "        return bm.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(txt: str):\n",
    "    \"\"\"\n",
    "    Function that preprocess text\n",
    "    using simple_preprocess from gensim.utils \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : str\n",
    "        text to be preprocessed\n",
    "    stemmer : PorterStemmer\n",
    "        stemmer that will be used\n",
    "    stop_words : set[str]\n",
    "        set of word that will be removed like \"and\", \"is\", ...\n",
    "    \"\"\"\n",
    "    data = simple_preprocess(txt.replace(\"$\", \"\").replace('\"', \"\").replace(\"'\", \"\"))\n",
    "    return [stemmer.stem(i) for i in data if i not in stop_words]\n",
    "\n",
    "# steeled from pv211_utils.systems import BM25PlusSystem (only change some default parameters and preprocess function)\n",
    "class my_BM25PlusSystem(IRSystemBase):\n",
    "    \"\"\"\n",
    "    Class for BM25+ ranking system. BM25+ is extension of BM25 - bag-of-words retrieval function that ranks a set of\n",
    "    documents based on the query terms appearing in each document, regardless of their proximity within the document.\n",
    "    Parameters\n",
    "    ----------\n",
    "    documents: OrderedDict\n",
    "        Input documents\n",
    "    k1: float\n",
    "        BM25 k1 parameter. k1 is a variable which helps determine term frequency saturation characteristics.\n",
    "    b: float\n",
    "        BM25 b parameter. With bigger b, the effects of the length of the document compared to the average\n",
    "        length are more amplified.\n",
    "    d: float\n",
    "        BM25 d parameter. Delta parameter for BM25+.\n",
    "    Attributes\n",
    "    ----------\n",
    "    bm25: BM25PlusCore\n",
    "        Ranking model\n",
    "    index: dict of (int, Document)\n",
    "        A mapping from indexed document numbers to documents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, documents,\n",
    "                 k1: float = 2, b: float = 0.001, d: float = 0.5):\n",
    "\n",
    "        docs_values = documents.values()\n",
    "\n",
    "        corpus = [preprocess_text(str(document)) for document in docs_values]\n",
    "\n",
    "        self.bm25 = BM25Plus(corpus, k1=k1, b=b, delta=d)\n",
    "        self.index = dict(enumerate(docs_values))\n",
    "\n",
    "    def search(self, query: QueryBase) -> Iterable[DocumentBase]:\n",
    "        \"\"\"\n",
    "        yield best docs by relevace\n",
    "        Parameters\n",
    "        ----------\n",
    "        query: QueryBase\n",
    "        \"\"\"\n",
    "        query = preprocess_text(str(query))\n",
    "\n",
    "        # score and rank docs by their relevance\n",
    "        docs = self.bm25.get_scores(query).argsort()[::-1]\n",
    "\n",
    "        for doc in docs:\n",
    "            yield self.index[doc]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwrCzoaZhWi4"
   },
   "source": [
    "## Evaluation\n",
    "Finally, we will evaluate your information retrieval system using [the Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision) (MAP) evaluation measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ssX-nvxGu3JK",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.arqmath.leaderboard import ArqmathLeaderboard\n",
    "from pv211_utils.arqmath.eval import ArqmathEvaluation\n",
    "\n",
    "submit_result = False\n",
    "author_name = 'Strompov√°, Al≈æbeta'\n",
    "\n",
    "test_queries = data.load_test_queries(Query)\n",
    "test_judgements = data.load_test_judgements()\n",
    "leaderboard = ArqmathLeaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% 10% 15% 20% 25% 30% 35% 40% 45% 50% 55% 60% 65% 70% 75% 80% 85% 90% 95% 100% "
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Your system achieved **28.82% MAP score**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Congratulations, you passed the **10%** minimum! ü•≥"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Set `submit_result = True` and write your name to the `author_name` variable to submit your result to [the leaderboard](https://docs.google.com/spreadsheets/d/e/2PACX-1vT9GibzjkZJxdFNdgr666TLDIHD46HfTYSEPeKUN-ErxRIN2HGjUtKyfvf6Xg3MZ6cW4p9qcSmR-4Rk/pubhtml?gid=0&single=true). üèÜ\n",
       "\n",
       "The best submissions on the leaderboard will receive *small awards during the semester*, and some *__seriously big__ awards* after the personal check at the end of the competition (2023-05-01). Please be polite, do not spoil the game for the others, and **have fun!** üòâ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system = IRSystem(answers)\n",
    "evaluation = ArqmathEvaluation(system, test_judgements, leaderboard=leaderboard, author_name=author_name)\n",
    "evaluation.evaluate(test_queries, submit_result)\n",
    "# 28.82"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xmpR8qpTZwyP",
    "y845E0ePZqeH",
    "gjzTmnjcrJVQ",
    "CwYwHs-MpD1_",
    "8psrfOlGH-hM",
    "xJM9TfbEPCZV"
   ],
   "name": "arqmath.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/MIR-MU/pv211-utils/blob/main/notebooks/arqmath.ipynb",
     "timestamp": 1681558107889
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "97b31d6e62de2216a05dd9342162045e53cee058ed98d00a361b193ba69cab9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
